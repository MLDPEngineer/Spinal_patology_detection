{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/protus/Documents/Projects/CompVision/models/RetinaNet\n",
      "Requirement already satisfied: keras in /home/protus/anaconda3/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (2.2.4)\n",
      "Requirement already satisfied: keras-resnet in /home/protus/.local/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (0.1.0)\n",
      "Requirement already satisfied: six in /home/protus/anaconda3/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (1.12.0)\n",
      "Requirement already satisfied: scipy in /home/protus/anaconda3/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (1.2.1)\n",
      "Requirement already satisfied: cython in /home/protus/anaconda3/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (0.29.6)\n",
      "Requirement already satisfied: Pillow in /home/protus/anaconda3/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (5.4.1)\n",
      "Requirement already satisfied: opencv-python in /home/protus/anaconda3/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (3.4.1.15)\n",
      "Requirement already satisfied: progressbar2 in /home/protus/.local/lib/python3.6/site-packages (from keras-retinanet==0.5.0) (3.39.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/protus/anaconda3/lib/python3.6/site-packages (from keras->keras-retinanet==0.5.0) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/protus/anaconda3/lib/python3.6/site-packages (from keras->keras-retinanet==0.5.0) (1.16.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/protus/anaconda3/lib/python3.6/site-packages (from keras->keras-retinanet==0.5.0) (1.0.6)\n",
      "Requirement already satisfied: h5py in /home/protus/anaconda3/lib/python3.6/site-packages (from keras->keras-retinanet==0.5.0) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/protus/anaconda3/lib/python3.6/site-packages (from keras->keras-retinanet==0.5.0) (3.12)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /home/protus/.local/lib/python3.6/site-packages (from progressbar2->keras-retinanet==0.5.0) (2.3.0)\n",
      "Building wheels for collected packages: keras-retinanet\n",
      "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-m1_9n713/wheels/db/19/93/887040e363fd576f16b32353fb13bae994c3bb1b796f8ee71f\n",
      "Successfully built keras-retinanet\n",
      "Installing collected packages: keras-retinanet\n",
      "  Found existing installation: keras-retinanet 0.5.0\n",
      "    Uninstalling keras-retinanet-0.5.0:\n",
      "      Successfully uninstalled keras-retinanet-0.5.0\n",
      "Successfully installed keras-retinanet-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!cd ./models/RetinaNet && pip install . --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet.models import load_model\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow relative imports when being executed as script.\n",
    "if __name__ == \"__main__\" and __package__ is None:\n",
    "    sys.path.insert(0, os.path.join(os.path.abspath(''), '..', '..'))\n",
    "    import keras_retinanet.bin  # noqa: F401\n",
    "    __package__ = \"keras_retinanet.bin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these to absolute imports if you copy this script outside the keras_retinanet package.\n",
    "from .. import layers  # noqa: F401\n",
    "from .. import losses\n",
    "from .. import models\n",
    "from ..callbacks import RedirectModel\n",
    "from ..callbacks.eval import Evaluate\n",
    "from ..models.retinanet import retinanet_bbox\n",
    "from ..preprocessing.csv_generator import CSVGenerator\n",
    "# from ..preprocessing.kitti import KittiGenerator\n",
    "# from ..preprocessing.open_images import OpenImagesGenerator\n",
    "# from ..preprocessing.pascal_voc import PascalVocGenerator\n",
    "from ..utils.anchors import make_shapes_callback\n",
    "from ..utils.config import read_config_file, parse_anchor_parameters\n",
    "from ..utils.keras_version import check_keras_version\n",
    "from ..utils.model import freeze as freeze_model\n",
    "from ..utils.transform import random_transform_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(path):\n",
    "    # Intended behavior: try to create the directory,\n",
    "    # pass if the directory exists already, fails otherwise.\n",
    "    # Meant for Python 2.7/3.n compatibility.\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    \"\"\" Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto(device_count = {'GPU': 0})#\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "\n",
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    \"\"\" Load weights for model.\n",
    "    Args\n",
    "        model         : The model to load weights for.\n",
    "        weights       : The weights to load.\n",
    "        skip_mismatch : If True, skips layers whose shape of weights doesn't match with the model.\n",
    "    \"\"\"\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0,\n",
    "                  freeze_backbone=False, lr=1e-5, config=None):\n",
    "    #backbone_retinanet(keras_model)\n",
    "    \"\"\" Creates three models (model, training_model, prediction_model).\n",
    "    Args\n",
    "        backbone_retinanet : A function to call to create a retinanet model with a given backbone.\n",
    "        num_classes        : The number of classes to train.\n",
    "        weights            : The weights to load into the model.\n",
    "        multi_gpu          : The number of GPUs to use for training.\n",
    "        freeze_backbone    : If True, disables learning for the backbone.\n",
    "        config             : Config parameters, None indicates the default configuration.\n",
    "    Returns\n",
    "        model            : The base model. This is also the model that is saved in snapshots.\n",
    "        training_model   : The training model. If multi_gpu=0, this is identical to model.\n",
    "        prediction_model : The model wrapped with utility functions to perform object detection (applies regression values and performs NMS).\n",
    "    \"\"\"\n",
    "\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # load anchor parameters, or pass None (so that defaults will be used)\n",
    "    anchor_params = None\n",
    "    num_anchors   = None\n",
    "    if config and 'anchor_parameters' in config:\n",
    "        anchor_params = parse_anchor_parameters(config)\n",
    "        num_anchors   = anchor_params.num_anchors()\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        from keras.utils import multi_gpu_model\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "    else:\n",
    "        model          = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=lr, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(model, training_model, prediction_model, validation_generator, args):\n",
    "    \"\"\" Creates the callbacks to use during training.\n",
    "    Args\n",
    "        model: The base model.\n",
    "        training_model: The model that is used for training.\n",
    "        prediction_model: The model that should be used for validation.\n",
    "        validation_generator: The generator for creating validation data.\n",
    "        args: parseargs args object.\n",
    "    Returns:\n",
    "        A list of callbacks used for training.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    tensorboard_callback = None\n",
    "\n",
    "#     if args.tensorboard_dir:\n",
    "#         tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "#             log_dir                = args.tensorboard_dir,\n",
    "#             histogram_freq         = 0,\n",
    "#             batch_size             = args.batch_size,\n",
    "#             write_graph            = False,\n",
    "#             write_grads            = True,\n",
    "#             write_images           = True,\n",
    "#             embeddings_freq        = 0,\n",
    "#             embeddings_layer_names = None,\n",
    "#             embeddings_metadata    = None\n",
    "#         )\n",
    "#         callbacks.append(tensorboard_callback)\n",
    "\n",
    "    if args.evaluation and validation_generator:\n",
    "        if args.dataset_type == 'coco':\n",
    "            from ..callbacks.coco import CocoEval\n",
    "\n",
    "            # use prediction model for evaluation\n",
    "            evaluation = CocoEval(validation_generator, tensorboard=tensorboard_callback)\n",
    "        else:\n",
    "            evaluation = Evaluate(validation_generator, \n",
    "                                  tensorboard=tensorboard_callback, \n",
    "                                  weighted_average=args.weighted_average)\n",
    "#             evaluation.set_model(prediction_model)\n",
    "        evaluation = RedirectModel(evaluation, prediction_model)\n",
    "        callbacks.append(evaluation)\n",
    "\n",
    "    # save the model\n",
    "    if args.snapshots:\n",
    "        # ensure directory created first; otherwise h5py will error after epoch.\n",
    "        makedirs(args.snapshot_path)\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(\n",
    "                args.snapshot_path,\n",
    "                '{backbone}_{dataset_type}_{{epoch:02d}}.h5'.format(backbone=args.backbone, dataset_type=args.dataset_type)\n",
    "            ),\n",
    "            verbose=1,\n",
    "            # save_best_only=True,\n",
    "            # monitor=\"mAP\",\n",
    "            # mode='max'\n",
    "        )\n",
    "        checkpoint = RedirectModel(checkpoint, model)\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "    callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor    = 'loss',\n",
    "        factor     = 0.1,\n",
    "        patience   = 2,\n",
    "        verbose    = 1,\n",
    "        mode       = 'auto',\n",
    "        min_delta  = 0.0001,\n",
    "        cooldown   = 0,\n",
    "        min_lr     = 0\n",
    "    ))\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(args, preprocess_image):\n",
    "    \"\"\" Create generators for training and validation.\n",
    "\n",
    "    Args\n",
    "        args             : parseargs object containing configuration for generators.\n",
    "        preprocess_image : Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size'       : args.batch_size,\n",
    "        'config'           : args.config,\n",
    "        'image_min_side'   : args.image_min_side,\n",
    "        'image_max_side'   : args.image_max_side,\n",
    "        'preprocess_image' : preprocess_image,\n",
    "    }\n",
    "\n",
    "    # create random transform generator for augmenting training data\n",
    "    if args.random_transform:\n",
    "        transform_generator = random_transform_generator(\n",
    "            min_rotation=-0.1,\n",
    "            max_rotation=0.1,\n",
    "            min_translation=(-0.1, -0.1),\n",
    "            max_translation=(0.1, 0.1),\n",
    "            min_shear=-0.1,\n",
    "            max_shear=0.1,\n",
    "            min_scaling=(0.9, 0.9),\n",
    "            max_scaling=(1.1, 1.1),\n",
    "            flip_x_chance=0.5,\n",
    "            flip_y_chance=0.5,\n",
    "        )\n",
    "    else:\n",
    "        transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "\n",
    "    if args.dataset_type == 'csv':\n",
    "        train_generator = CSVGenerator(\n",
    "            args.annotations,\n",
    "            args.classes,\n",
    "            transform_generator=transform_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        if args.val_annotations:\n",
    "            validation_generator = CSVGenerator(\n",
    "                args.val_annotations,\n",
    "                args.classes,\n",
    "                **common_args\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "            \n",
    "    else:\n",
    "        raise ValueError('Invalid data type received: {}'.format(args.dataset_type))\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(parsed_args):\n",
    "    \"\"\" Function to check for inherent contradictions within parsed arguments.\n",
    "    For example, batch_size < num_gpus\n",
    "    Intended to raise errors prior to backend initialisation.\n",
    "\n",
    "    Args\n",
    "        parsed_args: parser.parse_args()\n",
    "\n",
    "    Returns\n",
    "        parsed_args\n",
    "    \"\"\"\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and parsed_args.batch_size < parsed_args.multi_gpu:\n",
    "        raise ValueError(\n",
    "            \"Batch size ({}) must be equal to or higher than the number of GPUs ({})\".format(parsed_args.batch_size,\n",
    "                                                                                             parsed_args.multi_gpu))\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and parsed_args.snapshot:\n",
    "        raise ValueError(\n",
    "            \"Multi GPU training ({}) and resuming from snapshots ({}) is not supported.\".format(parsed_args.multi_gpu,\n",
    "                                                                                                parsed_args.snapshot))\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and not parsed_args.multi_gpu_force:\n",
    "        raise ValueError(\"Multi-GPU support is experimental, use at own risk! Run with --multi-gpu-force if you wish to continue.\")\n",
    "\n",
    "    if 'resnet' not in parsed_args.backbone:\n",
    "        warnings.warn('Using experimental backbone {}. Only resnet50 has been properly tested.'.format(parsed_args.backbone))\n",
    "\n",
    "    return parsed_args\n",
    "\n",
    "\n",
    "def parse_args(args):\n",
    "    \"\"\" Parse the arguments.\n",
    "    \"\"\"\n",
    "    parser     = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
    "    subparsers = parser.add_subparsers(help='Arguments for specific dataset types.', dest='dataset_type')\n",
    "    subparsers.required = True\n",
    "\n",
    "    coco_parser = subparsers.add_parser('coco')\n",
    "    coco_parser.add_argument('coco_path', help='Path to dataset directory (ie. /tmp/COCO).')\n",
    "\n",
    "    pascal_parser = subparsers.add_parser('pascal')\n",
    "    pascal_parser.add_argument('pascal_path', help='Path to dataset directory (ie. /tmp/VOCdevkit).')\n",
    "\n",
    "    kitti_parser = subparsers.add_parser('kitti')\n",
    "    kitti_parser.add_argument('kitti_path', help='Path to dataset directory (ie. /tmp/kitti).')\n",
    "\n",
    "    def csv_list(string):\n",
    "        return string.split(',')\n",
    "\n",
    "    oid_parser = subparsers.add_parser('oid')\n",
    "    oid_parser.add_argument('main_dir', help='Path to dataset directory.')\n",
    "    oid_parser.add_argument('--version',  help='The current dataset version is v4.', default='v4')\n",
    "    oid_parser.add_argument('--labels-filter',  help='A list of labels to filter.', type=csv_list, default=None)\n",
    "    oid_parser.add_argument('--annotation-cache-dir', help='Path to store annotation cache.', default='.')\n",
    "    oid_parser.add_argument('--parent-label', help='Use the hierarchy children of this label.', default=None)\n",
    "\n",
    "    csv_parser = subparsers.add_parser('csv')\n",
    "    csv_parser.add_argument('annotations', help='Path to CSV file containing annotations for training.')\n",
    "    csv_parser.add_argument('classes', help='Path to a CSV file containing class label mapping.')\n",
    "    csv_parser.add_argument('--val-annotations', help='Path to CSV file containing annotations for validation (optional).')\n",
    "\n",
    "    group = parser.add_mutually_exclusive_group()\n",
    "    group.add_argument('--snapshot',          help='Resume training from a snapshot.')\n",
    "    group.add_argument('--imagenet-weights',  help='Initialize the model with pretrained imagenet weights. This is the default behaviour.', action='store_const', const=True, default=True)\n",
    "    group.add_argument('--weights',           help='Initialize the model with weights from a file.')\n",
    "    group.add_argument('--no-weights',        help='Don\\'t initialize the model with any weights.', dest='imagenet_weights', action='store_const', const=False)\n",
    "\n",
    "    parser.add_argument('--backbone',         help='Backbone model used by retinanet.', default='resnet50', type=str)\n",
    "    parser.add_argument('--batch-size',       help='Size of the batches.', default=1, type=int)\n",
    "    parser.add_argument('--gpu',              help='Id of the GPU to use (as reported by nvidia-smi).')\n",
    "    parser.add_argument('--multi-gpu',        help='Number of GPUs to use for parallel processing.', type=int, default=0)\n",
    "    parser.add_argument('--multi-gpu-force',  help='Extra flag needed to enable (experimental) multi-gpu support.', action='store_true')\n",
    "    parser.add_argument('--epochs',           help='Number of epochs to train.', type=int, default=10)\n",
    "    parser.add_argument('--steps',            help='Number of steps per epoch.', type=int, default=100)#10000\n",
    "    parser.add_argument('--lr',               help='Learning rate.', type=float, default=1e-5)\n",
    "    parser.add_argument('--snapshot-path',    help='Path to store snapshots of models during training (defaults to \\'./snapshots\\')', default='./snapshots')\n",
    "    parser.add_argument('--tensorboard-dir',  help='Log directory for Tensorboard output', default='./logs')\n",
    "    parser.add_argument('--no-snapshots',     help='Disable saving snapshots.', dest='snapshots', action='store_false')\n",
    "    parser.add_argument('--no-evaluation',    help='Disable per epoch evaluation.', dest='evaluation', action='store_false')\n",
    "    parser.add_argument('--freeze-backbone',  help='Freeze training of backbone layers.', action='store_true')\n",
    "    parser.add_argument('--random-transform', help='Randomly transform image and annotations.', action='store_true')\n",
    "    parser.add_argument('--image-min-side',   help='Rescale the image so the smallest side is min_side.', type=int, default=800)\n",
    "    parser.add_argument('--image-max-side',   help='Rescale the image if the largest side is larger than max_side.', type=int, default=1333)\n",
    "    parser.add_argument('--config',           help='Path to a configuration parameters .ini file.')\n",
    "    parser.add_argument('--weighted-average', help='Compute the mAP using the weighted average of precisions among classes.', action='store_true')\n",
    "    parser.add_argument('--compute-val-loss', help='Compute validation loss during training', dest='compute_val_loss', action='store_true')\n",
    "\n",
    "    # Fit generator arguments\n",
    "    parser.add_argument('--workers', help='Number of multiprocessing workers. To disable multiprocessing, set workers to 0', type=int, default=1)\n",
    "    parser.add_argument('--max-queue-size', help='Queue length for multiprocessing workers in fit generator.', type=int, default=10)\n",
    "    \n",
    "\n",
    "    return check_args(parser.parse_args(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://vadimchibirev@bitbucket.org/vadimchibirev/spinal_pathology_analysis.git\n",
    "    \n",
    "# !cd spinal_pathology_analysis/models/RetinaNet && pip install . --user\n",
    "\n",
    "# !pip install --upgrade git+https://github.com/broadinstitute/keras-resnet\n",
    "# import keras\n",
    "# import keras_resnet\n",
    "\n",
    "# %cd /content/spinal_pathology_analysis\n",
    "\n",
    "# from spinal_pathology_analysis.models.RetinaNet.keras_retinanet.bin import train\n",
    "\n",
    "# args = \"csv /home/protus/Documents/Projects/CompVision/train_annotations.csv \\\n",
    "#         /home/protus/Documents/Projects/CompVision/classes.csv \\\n",
    "#         --val-annotations /home/protus/Documents/Projects/CompVision/valid_annotations.csv\".split()\n",
    "\n",
    "# train.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model, this may take a second...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "padding_conv1 (ZeroPadding2D)   (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9408        padding_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 res3b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 res3c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 res4b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 res4c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 res4d_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 res4e_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 \n",
      "                                                                 res4f_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               \n",
      "                                                                 C4_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  \n",
      "                                                                 res3d_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               \n",
      "                                                                 C3_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         \n",
      "                                                                 P4[0][0]                         \n",
      "                                                                 P5[0][0]                         \n",
      "                                                                 P6[0][0]                         \n",
      "                                                                 P7[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "classification_submodel (Model) (None, None, 2)      2401810     P3[0][0]                         \n",
      "                                                                 P4[0][0]                         \n",
      "                                                                 P5[0][0]                         \n",
      "                                                                 P6[0][0]                         \n",
      "                                                                 P7[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        \n",
      "                                                                 regression_submodel[2][0]        \n",
      "                                                                 regression_submodel[3][0]        \n",
      "                                                                 regression_submodel[4][0]        \n",
      "                                                                 regression_submodel[5][0]        \n",
      "__________________________________________________________________________________________________\n",
      "classification (Concatenate)    (None, None, 2)      0           classification_submodel[1][0]    \n",
      "                                                                 classification_submodel[2][0]    \n",
      "                                                                 classification_submodel[3][0]    \n",
      "                                                                 classification_submodel[4][0]    \n",
      "                                                                 classification_submodel[5][0]    \n",
      "==================================================================================================\n",
      "Total params: 36,403,702\n",
      "Trainable params: 36,297,462\n",
      "Non-trainable params: 106,240\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,256,200,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node res2a_branch2c/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@training/Adam/cond_3/Switch_2\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res2a_branch2b_relu/Relu, res2a_branch2c/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/add/_2237}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9103_loss/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f0b3e13fda2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mtrain_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'./DataSets/train_annotations.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalid_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'./DataSets/valid_annotations.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     classes=r'./DataSets/classes.csv')\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projects/CompVision/models/RetinaNet/keras_retinanet/bin/train.py\u001b[0m in \u001b[0;36mtrain_ipython\u001b[0;34m(dataset_len, batch_size, epochs, train_annotations, valid_annotations, classes, snapshots_dir)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_annotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/CompVision/models/RetinaNet/keras_retinanet/bin/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,256,200,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node res2a_branch2c/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@training/Adam/cond_3/Switch_2\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res2a_branch2b_relu/Relu, res2a_branch2c/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/add/_2237}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9103_loss/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "from models.RetinaNet.keras_retinanet.bin.train import train_ipython\n",
    "\n",
    "train_ipython(dataset_len=356, \n",
    "                    batch_size=1,\n",
    "                    epochs=2,\n",
    "                    train_annotations=r'./DataSets/train_annotations.csv',\n",
    "                    valid_annotations=r'./DataSets/valid_annotations.csv',\n",
    "                    classes=r'./DataSets/classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "# snapshots_dir = snapshots_dir if snapshots_dir else r'./snapshots'\n",
    "epochs = 2\n",
    "train_annotations=r'./DataSets/train_annotations.csv'\n",
    "valid_annotations=r'./DataSets/valid_annotations.csv'\n",
    "classes=r'./DataSets/classes.csv'\n",
    "\n",
    "assert train_annotations and valid_annotations and classes, \\\n",
    "    \"Не указаны: train_annotations, valid_annotations, classes\"\n",
    "\n",
    "args = \"--steps {0} \\\n",
    "    --epochs {1} \\\n",
    "    --weighted-average \\\n",
    "    --compute-val-loss \\\n",
    "    csv {2} \\\n",
    "    {3} \\\n",
    "    --val-annotations {4}\".format(steps, epochs, train_annotations, classes, valid_annotations).split()\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# parse arguments\n",
    "# args = \"--steps 10 \\\n",
    "#         --epochs 2 \\\n",
    "#         --weighted-average \\\n",
    "#         --compute-val-loss \\\n",
    "#         csv /home/protus/Documents/Projects/CompVision/train_annotations.csv \\\n",
    "#         /home/protus/Documents/Projects/CompVision/classes.csv \\\n",
    "#         --val-annotations /home/protus/Documents/Projects/CompVision/valid_annotations.csv\".split()\n",
    "#         --tensorboard-dir ./logs \\\n",
    "\n",
    "\n",
    "if args is None:\n",
    "    args = sys.argv[1:]\n",
    "args = parse_args(args)\n",
    "\n",
    "# create object that stores backbone information\n",
    "backbone = models.backbone(args.backbone) #ResNetBackbone\n",
    "\n",
    "# make sure keras is the minimum required version\n",
    "check_keras_version()\n",
    "\n",
    "# optionally choose specific GPU\n",
    "if args.gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "# optionally load config parameters\n",
    "if args.config:\n",
    "    args.config = read_config_file(args.config)\n",
    "\n",
    "# create the generators\n",
    "train_generator, validation_generator = create_generators(args, backbone.preprocess_image)\n",
    "\n",
    "# create the model\n",
    "if args.snapshot is not None:\n",
    "    print('Loading model, this may take a second...')\n",
    "    model            = models.load_model(args.snapshot, backbone_name=args.backbone)#KerasModel\n",
    "    training_model   = model\n",
    "    anchor_params    = None\n",
    "    if args.config and 'anchor_parameters' in args.config:\n",
    "        anchor_params = parse_anchor_parameters(args.config)\n",
    "    prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params) #?\n",
    "else:\n",
    "    weights = args.weights\n",
    "    # default to imagenet if nothing else is specified\n",
    "    if weights is None and args.imagenet_weights:\n",
    "        weights = backbone.download_imagenet()\n",
    "\n",
    "    print('Creating model, this may take a second...')\n",
    "    model, training_model, prediction_model = create_models(\n",
    "        backbone_retinanet=backbone.retinanet, #ResNet2D of keras_resnet здесь идет сборка всей модели\n",
    "        num_classes=train_generator.num_classes(),\n",
    "        weights=weights,\n",
    "        multi_gpu=args.multi_gpu,\n",
    "        freeze_backbone=args.freeze_backbone,\n",
    "        lr=args.lr,\n",
    "        config=args.config\n",
    "    )\n",
    "\n",
    "# print model summary\n",
    "# print(model.summary())\n",
    "\n",
    "# this lets the generator compute backbone layer shapes using the actual backbone model\n",
    "if 'vgg' in args.backbone or 'densenet' in args.backbone:\n",
    "    train_generator.compute_shapes = make_shapes_callback(model)\n",
    "    if validation_generator:\n",
    "        validation_generator.compute_shapes = train_generator.compute_shapes\n",
    "\n",
    "# create the callbacks\n",
    "callbacks = create_callbacks(\n",
    "    model,\n",
    "    training_model,\n",
    "    prediction_model,\n",
    "    validation_generator,\n",
    "    args,\n",
    ")\n",
    "\n",
    "# Use multiprocessing if workers > 0\n",
    "if args.workers > 0:\n",
    "    use_multiprocessing = True\n",
    "else:\n",
    "    use_multiprocessing = False\n",
    "\n",
    "if not args.compute_val_loss:\n",
    "    validation_generator = None\n",
    "\n",
    "# callbacks = []    \n",
    "# callbacks.append(TrainValTensorBoard(write_graph=False))\n",
    "# callbacks.append(TestTensorBoardCallback())\n",
    "# start training\n",
    "# training_model.fit_generator(\n",
    "#     generator=train_generator,\n",
    "#     steps_per_epoch=args.steps,\n",
    "#     epochs=args.epochs,\n",
    "#     verbose=1,\n",
    "#     callbacks=callbacks,\n",
    "#     workers=args.workers,\n",
    "#     use_multiprocessing=use_multiprocessing,\n",
    "#     max_queue_size=args.max_queue_size,\n",
    "#     validation_data=validation_generator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "raw_image    = train_generator.load_image(0)\n",
    "plt.imshow(raw_image)\n",
    "image        = train_generator.preprocess_image(raw_image.copy())\n",
    "plt.imshow(image)\n",
    "image, scale = train_generator.resize_image(image)\n",
    "plt.imshow(image)\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    image = image.transpose((2, 0, 1))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard.notebook\n",
    "# %tensorboard --logdir={'./logs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=args.steps,\n",
    "    epochs=args.epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    workers=args.workers,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    max_queue_size=args.max_queue_size,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'loss': 3.9879223346710204, 'regression_loss': 2.857790231704712, 'classification_loss': 1.1301321387290955, 'mAP': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'val_loss': 3.983213783649916, \n",
    "'val_regression_loss': 2.8568222087420776, \n",
    "'val_classification_loss': 1.126391564862112, \n",
    "'loss': 4.013098907470703, \n",
    "'regression_loss': 2.885668182373047, \n",
    "'classification_loss': 1.1274307131767274, \n",
    "'lr': 1e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
